---
author: Mario Parre√±o
date: 24/05/2021
image: ./images/dino/squaar.jpg
tags: ["computer vision", "transformer", "paper", "encoder", "self-supervised"]
title: DINO - Emerging Properties in Self-Supervised Vision Transformers
description: Unsupervised visual feature learning using knowledge distillation and transformers
draft: true
---

import Underlined from "../../components/blog/Underlined.astro";
import Table from "../../components/blog/Table.astro"
import SEOImage from "../../components/blog/SEOImage.astro";


## DINO Framework: Student-Teacher Training 

### Teacher training: EMA

### Preventing Collapse

### Multi-crop training

## Applications

### Feature extraction

### Feature visualization

## Extra: Code Repository

I have developed a repository with the code of the ViT, with the code
of the full model and the training process.
You can find it at <a href="https://github.com/AIdventures/microViT" target="_blank">microViT</a>.

Train your own ViT model from scratch and don't forget to star the repository if you like it!


## Credits

- [Paper - Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.14294)
- [DINO - Original Pytorch Implementation](https://github.com/facebookresearch/dino)